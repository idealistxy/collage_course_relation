## 生成数据
# 导⼊必要的库
import numpy as np
# 设置随机种⼦以确保结果可重复
np.random.seed(42)
# ⽣成第⼀个⾼斯分布的数据
mean1 = [0, 0, 0, 0, 0] # 均值向量
cov1 = np.eye(5) # 协⽅差矩阵（单位矩阵）
data1 = np.random.multivariate_normal(mean1, cov1, 100) # ⽣成100个样本
# ⽣成第⼆个⾼斯分布的数据
mean2 = [5, 5, 5, 5, 5]
cov2 = np.eye(5)
data2 = np.random.multivariate_normal(mean2, cov2, 100)
# ⽣成第三个⾼斯分布的数据
mean3 = [0, 5, 0, 5, 0]
cov3 = np.eye(5)
data3 = np.random.multivariate_normal(mean3, cov3, 100)
# ⽣成第四个⾼斯分布的数据
mean4 = [5, 0, 5, 0, 5]
cov4 = np.eye(5)
data4 = np.random.multivariate_normal(mean4, cov4, 100)
# ⽣成第五个⾼斯分布的数据
mean5 = [2.5, 2.5, 2.5, 2.5, 2.5]
cov5 = np.eye(5)

data5 = np.random.multivariate_normal(mean5, cov5, 100)
# 合并所有⽣成的数据
data = np.vstack((data1, data2, data3, data4, data5))
np.random.shuffle(data) # 打乱数据顺序
# 输出⽣成的数据形状
print("Data shape:", data.shape)
## 标准化处理
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
standerd_data = scaler.fit_transform(data)

## 降维
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# 保留2个主成分
pca = PCA(n_components=2)
# 拟合并变换数据
pca_data = pca.fit_transform(standerd_data)

# 绘制二维散点图
plt.figure(figsize=(8, 6))
plt.scatter(pca_data[:, 0], pca_data[:, 1], c='blue', marker='o', edgecolor='k')

# 添加图表标题和坐标轴标签
plt.title('PCA Result')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')

# 显示图表
plt.grid(True)
plt.show()

## 高斯混合模型聚类
from sklearn.mixture import GaussianMixture

# 初始化GaussianMixture，设定聚类数量
gmm = GaussianMixture(n_components=5)

# 拟合数据
gmm.fit(pca_data)

# 预测每个样本的类别
labels = gmm.predict(pca_data)
## 结果可视化
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse
from matplotlib.colors import ListedColormap

# 获取每个聚类的中⼼（均值）
centers = gmm.means_
covariances = gmm.covariances_

# 定义可视化函数
def plot_gmm(data, labels, centers, covariances, ax):
    ax.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis', marker='o', edgecolor='k', s=30)
    colors = ListedColormap(['#FF6347', '#4682B4', '#32CD32', '#FFD700', '#FF69B4'])
    for i in range(centers.shape[0]):
        center = centers[i]
        covariance = covariances[i][:2, :2]  # 提取前两维度的协方差矩阵
        eigenvalues, eigenvectors = np.linalg.eigh(covariance)
        order = eigenvalues.argsort()[::-1]
        eigenvalues, eigenvectors = eigenvalues[order], eigenvectors[:, order]
        angle = np.arctan2(eigenvectors[1, 0], eigenvectors[0, 0])
        width, height = 2 * np.sqrt(eigenvalues)
        ellipse = Ellipse(center, width, height, angle=np.degrees(angle), edgecolor=colors(i), facecolor=colors(i), alpha=0.75)
        ax.add_patch(ellipse)
        ax.scatter(center[0], center[1], c='red', s=100, marker='x')


# 绘制聚类结果
fig, ax = plt.subplots(figsize=(10, 8))
plot_gmm(pca_data, labels, centers, covariances, ax)
ax.set_title('Gaussian Mixture Clustering with Ellipses')
ax.set_xlabel('Principal Component 1')
ax.set_ylabel('Principal Component 2')
ax.grid(True)
plt.show()

## 示例二
# 导⼊必要的库
import numpy as np
from sklearn.datasets import fetch_lfw_people
from sklearn.preprocessing import StandardScaler
# 下载LFW⼈脸数据集
lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)
X = lfw_people.data # 提取图像数据
n_samples, h, w = lfw_people.images.shape # 获取图像的尺⼨
# 输出数据形状
print("Number of samples:", n_samples)
print("Image height:", h)
print("Image width:", w)
# 数据标准化处理
scaler = StandardScaler()
X_normalized = scaler.fit_transform(X)
# 输出标准化后的数据形状
print("Normalized data shape:", X_normalized.shape)

## 提取特征和降维
from sklearn.decomposition import PCA

# 保留150个主成分
pca = PCA(n_components=150)
# 拟合并变换数据
pca_X = pca.fit_transform(X_normalized)
## 高斯混合模型初始化和训练
from sklearn.mixture import GaussianMixture

# 初始化GaussianMixture，设定聚类数量
gmm = GaussianMixture(n_components=7)

# 拟合数据
gmm.fit(pca_X)

# 预测每个样本的类别
labels = gmm.predict(pca_X)

# 打印GMM参数
means = gmm.means_
covariances = gmm.covariances_
weights = gmm.weights_

print("GMM means:", means)
print("GMM covariances:", covariances)
print("GMM weights:", weights)
def plot_gallery(images, titles, h, w, n_row=2, n_col=4):
    """打印中心图像"""
    n_images = images.shape[0]
    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))
    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)
    for i in range(min(n_row * n_col, n_images)):
        plt.subplot(n_row, n_col, i + 1)
        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)
        plt.title(titles[i], size=12)
        plt.xticks(())
        plt.yticks(())

# 获取每个聚类的中⼼（均值），并将PCA空间中的均值逆变换回原始图像空间
faces_means = pca.inverse_transform(means)

# 使⽤定义的函数绘制聚类中⼼的⾯部图像。
titles = [f'Cluster {i+1}' for i in range(7)]
plot_gallery(faces_means, titles, h, w)
plt.show()
import numpy as np
from sklearn.datasets import fetch_lfw_people
from sklearn.preprocessing import StandardScaler
from sklearn.mixture import GaussianMixture
import matplotlib.pyplot as plt
import cv2

# 下载LFW人脸数据集
lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)
X = lfw_people.data  # 提取图像数据
n_samples, h, w = lfw_people.images.shape  # 获取图像的尺寸

# 输出数据形状
print("Number of samples:", n_samples)
print("Image height:", h)
print("Image width:", w)

# 数据标准化处理
scaler = StandardScaler()
X_normalized = scaler.fit_transform(X)

# 初始化GaussianMixture，设定聚类数量
gmm = GaussianMixture(n_components=7)
# 拟合数据
gmm.fit(X_normalized)

# 预测每个样本的类别
labels = gmm.predict(X_normalized)

# 打印GMM参数
means = gmm.means_
covariances = gmm.covariances_
weights = gmm.weights_

print("GMM means:", means)
print("GMM covariances:", covariances)
print("GMM weights:", weights)

def plot_gallery(images, titles, h, w, n_row=2, n_col=4):
    """打印中心图像"""
    n_images = images.shape[0]
    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))
    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)
    for i in range(min(n_row * n_col, n_images)):
        plt.subplot(n_row, n_col, i + 1)
        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)
        plt.title(titles[i], size=12)
        plt.xticks(())
        plt.yticks(())

# 反标准化聚类中心
faces_means_original = scaler.inverse_transform(means)

# 调整图片清晰度和增强对比度
faces_means_enhanced = []
for face in faces_means_original:
    # 调整图片尺寸
    face_img = face.reshape((h, w))
    face_img_resized = cv2.resize(face_img, (w*2, h*2), interpolation=cv2.INTER_CUBIC)
    
    # 直方图均衡化
    face_img_resized = cv2.equalizeHist(np.uint8(face_img_resized))
    
    faces_means_enhanced.append(face_img_resized)

faces_means_enhanced = np.array(faces_means_enhanced)

# 使用定义的函数绘制聚类中心的面部图像
titles = [f'Cluster {i+1}' for i in range(7)]
plot_gallery(faces_means_enhanced, titles, h*2, w*2)
plt.show()
